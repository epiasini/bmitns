{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/epiasini/bmitns/blob/main/lecture_5/Binary-classification.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install numpy scipy matplotlib ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import norm, binom\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the experiment\n",
    "We perform a classification experiment, where the stimulus $s$ could belong to one of two classes (which we call $1$ and $0$ by convention). For instance, we may show to the subject an oriented grating of variable orientation $s$, and we ask the subject to report whether the grating is oriented to the left $s<0$ or to the right $s>0$.\n",
    "\n",
    "<img src='grating.png' width=\"100\">\n",
    "\n",
    "In the lab, we perform $N$ trials and for each trial $t$ we record:\n",
    "- the true value of the stimulus, $s_t$ (which is known to us, - we are the ones generating the stimulus, so we know its true value\n",
    "- the class reported by the subject, $\\hat{c}_t$. We can indicate our experimental dataset $\\mathcal{D}$ with the notation $\\mathcal{D}=\\left\\{(s_t,\\hat{c}_t)\\right\\}_{t=1}^N$.\n",
    "\n",
    "# Building the model\n",
    "To build our model of perception we make the following assumptions:\n",
    "- the **prior** is flat: $p(c=1) = p(c=0) = 1/2$\n",
    "- the **class-conditional stimulus densities** (CCSD) are mirror-symmetric: $p(s|c=0) = p(-s|c=1)$. A simple case satisfying this condition is when $c=1$ means that $s$ is sampled uniformly from a set of possible positive values $0 < s_1 < s_2, \\ldots, S_K$, and $c=0$ means that $s$ is sampled uniformly from the set of corresponding negative values: $0 > -s_1 > -s_2 > \\ldots > -S_K$, like in the figure below. For concreteness, this is the case we will use in this notebook.\n",
    "\n",
    "<img src='ccsd_discrete.png' width=\"400\">.\n",
    "\n",
    "However, the results don't change as long as the CCSDs maintain the same symmetry, like these ones:\n",
    "\n",
    "<img src='ccsd_skewed_gaussian.png' width=\"400\">\n",
    "\n",
    "- the **measurement distribution**/likelihood function is, as usual, Gaussian: $p(x|s) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left[\\frac{-(x-s)^2}{2\\sigma^2}\\right]$\n",
    "\n",
    "By applying our usual method, we have built a model of the perceptual process, and we have solved it to obtain the **response distribution**:\n",
    "\n",
    "$$\n",
    "p(\\hat{c}|s) = \\Phi\\left(\\frac{s}{\\sigma}\\right) = \\int_{-\\infty}^s ds' \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left[-\\frac{s'^2}{2\\sigma^2}\\right]\n",
    "$$\n",
    "where $\\Phi(z)$ is the cumulative Gaussian function (the integral of a Gaussian pdf from $-\\infty$ to z)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model\n",
    "Our model has a free parameter, $\\sigma$, representing the sensory noise. This parameter is unknown, and we wish to estimate it based on the data we have recorded in the lab. There are many ways of doing this, but the most common is to **perform a maximum-likelihood fit**. \n",
    "\n",
    "We start by defining the likelihood of our model,\n",
    "$$\n",
    "\\mathcal{L}(\\sigma) = p(\\mathcal{D}|\\sigma)\n",
    "$$\n",
    "Note that **this is just a measure of the degree to which the model describes the data; it is not directly related to any of the functions we used to build the Bayesian model that culminated in the response distribution** (although of course it is derived from them, and has an analogous mathematical role). When we built the model, we also had a likelihood function $p(x|s)$, the likelihood for one value of the stimulus $s$ after observing the *measurement* $x$. These are completely different objects: $p(x|s)$ is related to the inference process that the **subject** performs to estimate the stimulus $s$ from the measurement $x$ in an experimental trial, while $p(\\mathcal{D}|\\sigma)$ is related to the inference process that the **experimenter** performs to estimate $\\sigma$ from the data $\\mathcal{D}$ collected during the course of the experiment.\n",
    "\n",
    "The model likelihood is simply, by definition, the probability of observing the data we have observed, given a particular value of $\\sigma$. If we had only observed a single trial, with stimulus $s$, this would be:\n",
    "- $\\mathcal{L}(\\sigma) = p(\\hat{c}=1|s)$ if the subject response on that trial was $\\hat{c}=1$, or \n",
    "- $\\mathcal{L}(\\sigma) = p(\\hat{c}=0|s) = 1-p(\\hat{c}=1|s)$ if the response was $\\hat{c}=0$.\n",
    "\n",
    "However, our dataset $\\mathcal{D}$ is composed by many trials. Since each trial is statistically independent, to obtain the probability of observing all of them we can simply multiply the probabilities calculated for each individual trial. To do so, we divide them in two different sets, the set of trials where the response was $\\hat{c}=1$ and the set of trials where the response was $\\hat{c}=0$. We get:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\sigma) = p(\\mathcal{D}|\\sigma) = \\prod_{t:\\hat{c}_t=1}p(\\hat{c}=1|s_t) \\times \\prod_{t:\\hat{c}_t=0}p(\\hat{c}=0|s_t)\\\\\n",
    " = \\prod_{t:\\hat{c}_t=1}p(\\hat{c}=1|s_t) \\times \\prod_{t:\\hat{c}_t=0}\\left[1-p(\\hat{c}=1|s_t)\\right]\n",
    "$$\n",
    "\n",
    "Now we use a trick: remembering that, for any $x$, $x^1=x$ and $x^0=1$, we can re-write this product as\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\sigma) = \\prod_{t=1}^N p(\\hat{c}=1|s_t)^{\\hat{c}_t} \\times \\left[1-p(\\hat{c}=1|s_t)\\right]^{(1-\\hat{c}_t)}\\\\\n",
    "= \\prod_{t=1}^N \\Phi\\left(\\frac{s_t}{\\sigma}\\right)^{\\hat{c}_t} \\times \\left[1-\\Phi\\left(\\frac{s_t}{\\sigma}\\right)\\right]^{(1-\\hat{c}_t)}\n",
    "$$\n",
    "\n",
    "This is because on the trials where $\\hat{c}_t=1$ the second term of the product above will be raised to the zeroth power (if $\\hat{c}_t=1$, then $1-\\hat{c}_t=0$) and therefore it will not contribute to the product - again, because anything raised to the zeroth power is 1 and multiplying anything by 1 does not make any difference. Conversely, on the trials where $\\hat{c}_t=0$ the first term of the product will not contribute, leaving only the second.\n",
    "\n",
    "Now we have our likelihood function, which depends on $\\sigma$ through the fact that the response distribution $p(\\hat{c}=1|s)$ depends on $\\sigma$ (remember, $p(\\hat{c}=1|s)=\\Phi(s/\\sigma))$. We want to find the value of $\\sigma$ that maximises $\\mathcal{L}$. Before doing so, for convenience we take the logarithm of the likelihood (this makes no difference in terms of maximising the function). Remembering the general property of the logarithm that\n",
    "\n",
    "$$\n",
    "\\ln (a^c\\cdot b^d) = c\\ln(a) + d\\ln(b)\n",
    "$$\n",
    "\n",
    "we can write our **log likelihood** as\n",
    "\n",
    "$$\n",
    "\\ln \\mathcal{L}(\\sigma) = \\sum_{t=1}^N\\left[\\hat{c}_t\\ln p(\\hat{c}=1|s_t) + \\left(1-\\hat{c}_t\\right)\\ln\\left(1-p(\\hat{c}=1|s_t)\\right)\\right]\\\\\n",
    " = \\sum_{t=1}^N\\left[\\hat{c}_t\\ln \\Phi(s_t/\\sigma) + \\left(1-\\hat{c}_t\\right)\\ln\\left(1-\\Phi(s_t/\\sigma)\\right)\\right]\n",
    "$$\n",
    "\n",
    "At this point we are done. In the expression above, $\\Phi$ is a known function, implemented in any language, and $s_t$ and $\\hat{c}_t$ are what makes up our experimental data. The only unknown is $\\sigma$. We can then **plug this function into any numerical optimization algorithm** (which you can find built-in into all scientific/data oriented languages and packages, Python/Julia/R/Matlab...) **to find the value of $\\sigma$ that maximises $\\mathcal{L}$**.\n",
    "\n",
    "Now, this is a sum over all trials. We can simplify this expression further if we use the assumption that $s$ can have only a finite number of values, $s=-s_K, -s_{K-1},\\ldots,-s_{1}, s_1, s_2, \\ldots, s_{K-1}, s_K$. If this is the case, we can break up the sum into $2K$ smaller sums, each running over all trials that had a given value of $s$.\n",
    "\n",
    "$$\n",
    "\\ln \\mathcal{L}(\\sigma) = \\sum_{s=-s_k}^{s_K}\\sum_{t:s_t=s} \\left[\\hat{c}_t\\ln p(\\hat{c}=1|s) + \\left(1-\\hat{c}_t\\right)\\ln\\left(1-p(\\hat{c}=1|s)\\right)\\right]\n",
    "$$\n",
    "\n",
    "Now, if we define:\n",
    "- $n_s$ = number of trials where the stimulus was $s$\n",
    "- $l_s$ = number of trials where the stimulus was $s$ **and** the response was $\\hat{c}=1$\n",
    "we get:\n",
    "\n",
    "$$\n",
    "\\ln \\mathcal{L}(\\sigma) = \\sum_{s=-s_K}^{s_K} \\left[l_s \\ln p(\\hat{c}=1|s) + (n_s-l_s) \\ln\\left(1-p(\\hat{c}=1|s)\\right)\\right] \\\\\n",
    "= \\sum_{s=-s_K}^{s_K} \\left[l_s \\ln \\Phi(s/\\sigma) + (n_s-l_s) \\ln\\left(1-\\Phi(s/\\sigma)\\right) \\right] \\\\\n",
    "$$\n",
    "\n",
    "which is a very simple expression depending only on the stimulus values $s$ and the **counts** of how many trials there were for that stimulus values and in how many of those trials the subject reported $c=1$. And of course on $\\sigma$, as the only free parameter of our model. Again, we can now take this expression and feed it to some optimization algorithm to find numerically the value of $\\sigma$ that gives the largest $\\ln \\mathcal{L}(\\sigma)$.\n",
    "\n",
    "## Extra: an alternative derivation\n",
    "We note that we can arrive at the expression above by an alternative, more direct path, assuming that we are already familiar with the [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution). Our model says that every time that we ask the subject to classify stimulus $s$, the subject will report $\\hat{c}=1$ with a given probability $p(\\hat{c}=1|s)=\\Phi(s/\\sigma)$. We have also assumed that there are $n_s$ trials for each level of the stimulus $s$, and that the subject has actually reported $\\hat{c}=1$ in $l_s$ of them. We can recognize this as the description of a **binomial process**, where the number of \"successes\" $l_s$ at each level depends on the number of attempts $n_s$ and the probability of success $p(\\hat{c}=1|s)$. If we define a new dataset\n",
    "\n",
    "$$\\mathcal{D}'=\\left\\{(n_s, l_s)\\right\\}_{s=-s_K}^{s_K}$$\n",
    "\n",
    "(where the data is the same as in the original $\\mathcal{D}$, but we represent it as a series of counts instead of a series of stimulus-report pairs), then we can directly write likelihood of the model with respect to this dataset as a product of binomial likelihoods (one per level of the stimulus):\n",
    "\n",
    "$$\n",
    "p(\\mathcal{D}'|\\sigma) = \\prod_{s=-s_K}^{s_K}\\binom{n_s}{l_s}\\left[p(\\hat{c}=1|s)\\right]^{l_s}\\left[1-p(\\hat{c}=1|s)\\right]^{n_s-l_s}\n",
    "$$\n",
    "\n",
    "Unsurprisingly, if we take the log we find that this likelihood is closely related to the one we derived above:\n",
    "\n",
    "$$\n",
    "\\ln p(\\mathcal{D}'|\\sigma) = \\ln p(\\mathcal{D}|\\sigma) + \\sum_s \\ln\\binom{n_s}{l_s}\n",
    "$$\n",
    "\n",
    "<font color=red>**Question/exercise:**</font> where does this difference come from, conceptually? How come we have two different likelihoods for the same data and the same model? Does it matter which one we use to find the best value of $\\sigma$ for the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Simulation\n",
    "Now we create a simulated experiment. An instance of the experiment is defined by a true value for $\\sigma$ and a value of the total number $N$ of trials in the experiment (other parameters such as the values taken by the stimulus $s$ are hardcoded below for simplicity). With rather poor coding practice, we encapsulate everything into a function `plot_psychometric` that generates the simulated data, fits the ideal observer to obtain an estimate of $\\sigma$ from the data, and then makes a plot showing the \"ground truth\" psychometric, the simulated data, and the fitted psychometric.\n",
    "\n",
    "Note that this is a key advantage of our modeling framework: our Bayesian models of perception are **generative models**. They allow our experiment + analysis to be tested out in simulation before we collect any data in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(σ, choice_1_counts, s_levels, n_trials_per_levels):\n",
    "    l_s = choice_1_counts\n",
    "    s = s_levels\n",
    "    n_s = n_trials_per_levels\n",
    "    # In principle, the following is the definition as per the expressions derived above.\n",
    "    #     However, scipy provides a special function to compute \"log of a cumulative gaussian\",\n",
    "    #     which is a bit better from a numerical standpoint than just writing np.log(norm.cdf(...)).\n",
    "    #     So we comment out the \"literal\" implementation of our likelihood, and use the more\n",
    "    #     sophisticated one instead.\n",
    "    # return (l_s*np.log(norm.cdf(s/σ)) + (n_s-l_s)*np.log(1-norm.cdf(s/σ))).sum()\n",
    "    return (l_s*scipy.special.log_ndtr(s_levels/σ) + (n_s-l_s)*scipy.special.log_ndtr(-s/σ)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psychometric(σ, N, display_behavioral_variance):\n",
    "    \n",
    "    # values of s to be used\n",
    "    s_levels = np.array([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "    # relative amount of trials to be allocated to each level. By default this is uniform (all numbers are equal),\n",
    "    #     but you can try changing it to see what happens. Note that if you \"weigh\" one stimulus level\n",
    "    #     a lot by putting more trials there than in other levels, the fit will automatically value that\n",
    "    #     datapoint more than the others, trying to make the fitted curve approach more the data at that point.\n",
    "    #     This is very useful, as often in the lab one ends up with more data in certain conditions than others.\n",
    "    trial_distribution = np.array([1,1,1,1,1,1,1,1,1])\n",
    "    # number of trials per level of the stimulus. This is just the total number N, divided among the\n",
    "    #     levels according to the ratios in trial_distributions above.\n",
    "    n_trials_per_level = (N*trial_distribution/trial_distribution.sum()).round().astype('int')\n",
    "    \n",
    "    # compute probability of choosing category c=+1 for each stimulus level in the experiment\n",
    "    p = norm.cdf(s_levels/σ)\n",
    "    \n",
    "    # generate empirical data: for each level, sample n_trials_per_level choices from a Binomial distribution\n",
    "    l = binom.rvs(n_trials_per_level, p)\n",
    "    \n",
    "    # fit empirical data with psychometric function. Note that our optimization library\n",
    "    #     can find *minima*, not *maxima* of functions, so instead of directly maximising\n",
    "    #     the log-likelihood we minimize the \"minus log likelihood\" (which is the same).\n",
    "    def function_to_be_minimized(σ):\n",
    "        return -log_likelihood(σ, l, s_levels, n_trials_per_level)\n",
    "    \n",
    "    # x0 here is an \"initial guess\" for the value of σ, needed for the optimization\n",
    "    #     procedure. The results should be robust to this choice. \"bounds\" is needed to\n",
    "    #     tell the optimizer that it shouldn't try negative values of σ.\n",
    "    σ_fit = scipy.optimize.minimize(function_to_be_minimized, x0=[0.5], bounds=[(0.01, None)]).x[0]\n",
    "    \n",
    "    # plot theoretical psychometric function\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    s_plot_range = np.linspace(s_levels.min(), s_levels.max(), 100)\n",
    "    p_plot = norm.cdf(s_plot_range/σ)\n",
    "    ax.plot(s_plot_range, p_plot, color='blue', label='Theoretical (ground-truth) psychometric')\n",
    "    \n",
    "    # display behavioral variance expected from the model (std. dev. of the Binomial distribution\n",
    "    #     associated with the number of \"report +1\" at each stimulus level).\n",
    "    if display_behavioral_variance:\n",
    "        ax.errorbar(s_levels, p, np.sqrt(n_trials_per_level*p*(1-p))/n_trials_per_level,\n",
    "                    linestyle='', color='blue')\n",
    "    \n",
    "    # plot empirical data\n",
    "    ax.scatter(s_levels, l/n_trials_per_level, color='red', label=\"Simulated data\", zorder=10)\n",
    "    \n",
    "    # plot fit to empirical data\n",
    "    ax.plot(s_plot_range, norm.cdf(s_plot_range/σ_fit), color='red', label='Psychometric curve fit to data')\n",
    "    \n",
    "    # display true and fitted value of sensory noise\n",
    "    ax.text(\n",
    "        0.95, 0.05,\n",
    "        f'$\\sigma_{{\\mathrm{{true}}}}={σ:.2f}$\\n$\\sigma_{{\\mathrm{{fit}}}}={σ_fit:.2f}$',\n",
    "        transform=ax.transAxes, fontsize=14, verticalalignment='bottom', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # cosmetic adjustments\n",
    "    ax.set_xlabel(\"Stimulus s\")\n",
    "    ax.set_ylabel(\"Fraction of 'choose +1'\")\n",
    "    ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909d0491a7994c7782d047efd9743b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='σ (Sensory noise)', max=5.0, min=0.01, step=0.01, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layout = widgets.Layout(width='auto', height='40px') #set width and height\n",
    "\n",
    "interactive(plot_psychometric,\n",
    "            σ=widgets.FloatSlider(\n",
    "                value=1, min=0.01, max=5, step=0.01,\n",
    "                description='σ (Sensory noise)', style={'description_width': 'initial'}),\n",
    "            N=widgets.IntSlider(\n",
    "                value=100, min=10, max=1000, step=1,\n",
    "                description='Total number of trials', style={'description_width': 'initial'}),\n",
    "            display_behavioral_variance=widgets.Checkbox(\n",
    "                value=False,\n",
    "                description='Display behavioral variance', style={'description_width': 'initial'})\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other diagrams\n",
    "Please disregard this section, these are just the diagrams used above in the explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3), constrained_layout=True)\n",
    "\n",
    "s_vals = np.arange(0.5, 2.6, 0.5)\n",
    "\n",
    "ax.axhline(0, color='dimgray', linewidth=0.5)\n",
    "ax.axvline(0, color='dimgray', linewidth=0.5)\n",
    "markerline, stemlines, baseline = ax.stem(s_vals, np.full_like(s_vals, 1/s_vals.size), basefmt='')\n",
    "plt.setp(stemlines, color='orange')\n",
    "plt.setp(markerline, color='orange')\n",
    "plt.setp(baseline, linestyle='')\n",
    "markerline, stemlines, baseline = ax.stem(-s_vals, np.full_like(s_vals, 1/s_vals.size), basefmt='')\n",
    "plt.setp(stemlines, color='green')\n",
    "plt.setp(markerline, color='green')\n",
    "plt.setp(baseline, linestyle='')\n",
    "\n",
    "ax.set_ylim(0,0.3)\n",
    "\n",
    "ax.text(1.5, 0.25, 'p(s|c=1)', horizontalalignment='center', color='orange')\n",
    "ax.text(-1.5, 0.25, 'p(s|c=0)', horizontalalignment='center', color='green')\n",
    "\n",
    "ax.set_xlabel('Stimulus s')\n",
    "ax.set_ylabel('Class-conditional stimulus density');\n",
    "\n",
    "fig.savefig('ccsd_discrete.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3), constrained_layout=True)\n",
    "x = np.linspace(-4.5,4.5,200)\n",
    "\n",
    "def skewed_normal(x, skewness):\n",
    "    return 2*norm.pdf(x)*norm.cdf(skewness*x)\n",
    "\n",
    "skewness = 3\n",
    "ax.axhline(0, color='dimgray', linewidth=0.5)\n",
    "ax.axvline(0, color='dimgray', linewidth=0.5)\n",
    "ax.fill_between(x, skewed_normal(x-0.5,skewness), facecolor='orange', alpha=0.4, edgecolor='black')\n",
    "ax.fill_between(x, skewed_normal(-x-0.5,skewness), color='green', alpha=0.4, edgecolor='black')\n",
    "ax.text(2, 0.3, 'p(s|c=1)', horizontalalignment='left', color='orange')\n",
    "ax.text(-2, 0.3, 'p(s|c=0)', horizontalalignment='right', color='green')\n",
    "ax.set_xlabel('Stimulus s')\n",
    "ax.set_ylabel('Class-conditional stimulus density');\n",
    "fig.savefig('ccsd_skewed_gaussian.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
